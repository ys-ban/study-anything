본 마크다운은 당일 작업 개요, 데이터셋, 모델, 결과를 주축으로 작성됩니다.


# Day 1
- 개요
    - 첫 날이기에 EDA 중심으로 수행
    - daily mission으로 baseline code 제출이 있음
- 데이터셋
    - 사용자의 구매기록을 담은 로그 데이터
    - 일정 기간 후 전혀 등장하지 않는 사용자가 존재
    - 실제 사용자가 아닌 서버 관리용 계정으로 추정되는 사용자가 있음
    - 2년 동안의 데이터에 추세성이 뚜렷하지 않음
- 모델
    - 의사결정나무 형태의 3가지 모델이 baseline으로 주어짐
    - LightGBM 기반
- 결과
    - out-of-fold 형식으로 검증을 한 baseline3이 가장 좋은 성능
    - AUC 0.8100
   


# Day 2
- 개요
    - 데이터 중 구매한 물건을 종류별로 구분한다면 유의미성을 발견할 수 있을 것이라 가정
    - 종류별로 구분된 물건은 구매의 주기성이나 발견하지 못한 특징을 발견할 수 있을 것이라 생각
- 데이터셋
    - 동시에 구매된(같은 order id 값을 가진) 상품은 연관성이 있을 것으로 판단
    - 위 사건은 co-occurence라 가정하여 word ebedding 기법을 적용 가능하다 판단
    - co-occurence을 만들기 위한 작업 진행
- 모델
    - 변함 없음
- 결과
    - co-occurence matrix 코드 완성
    


# Day 3
- 개요
    - co-occurence를 이용한 임베딩
    - PCA와 군집분석
    - 분포가 비선형적이기에 사분위수 중심으로 매달 데이터 확인 필요
- 데이터셋
    - gensim을 활용하여 word2vec 임베딩 추출
    - glove을 활용하여 임베딩 추출
    - 매달 고객별 구매량의 사분위수 산출
- 모델
    - sklearn을 활용하여 계층적 군집분석 수행
    - 산출된 사분위수를 시각화
- 결과
    - 군집분석 수행 후 PCA를 이용해 시각화했지만 물품 간 크게 구분되지 못함
    - 군집별 통계치(평균, 최대, 최소, 중위수 등) 주기성을 확인해봤으나 발견 안됨
    - 군집분석, 임베딩은 기각
    - 특정 달에 구매를 행한 고객의 구매 총액 제1사분위수(하위25%)가 300 안팍
    - 어떤 고객이 특정 달에 구매를 행했다면 그 고객의 구매 총액이 300을 넘을 확률은 약 75%임



# Day 4
- 개요
    - 최근 몇 달의 소비로 다음 달 소비를 예측할 수 있다는 가정으로 모델 구축 예정
    - 다음 달에 구매를 할지 안할지를 맞추면 됨
    - 시계열이 아닌 DT로 접근(시계열로 적합하기에는 미관측 기간이 너무 많음)
    - 여러 실험이 가능한 형태로 코드 작성
- 데이터셋
    - 최근 일주일, 보름, 한 달, 두 달, 세 달, 6개월의 거래내역의 통계치 산출 예정(코드 미완성)
    - 기본 imputing은 median이었으나 이는 불합리하다고 봄
    - 거래내역이 없어서 NaN 값이 발생했기 때문에 이를 상수 0으로 대체하는 것이 맞다고 봄
    - 통계치는 최대, 최소, 평균, 표준편차, 합, 왜도를 사용
    - 현재 baseline은 train의 경우 23개월치 데이터, test는 24개월치 데이터를 사용하기에 학습시 threshold를 조정하는 것이 성능을 높힐 수 있을 것이라 예측
- 모델
    - baseline3의 모델을 그대로 유지
- 결과
    - baseline3에서 imputing만 상수 0으로 바꾼 결과 AUC 0.8107
    - baseline3에서 threshold를 320으로 바꾼 결과 AUC 0.8091
    - baseline3에서 imputing 상수 0, threshold를 320으로 바꾼 결과 AUC 0.8091



# Day 5
- 개요
    - 지정한 각각의 기간의 통계치를 산출하는 함수 완성 목표
    - 완성된 feature를 이용해 피보팅
- 데이터셋
    - 기간별 통계치 산출 함수 완성 후 적용 -> feature 개수 700여개
    - imputing을 0이 아닌 -1로 변경(min이나 skew의 경우 음수가 나올 수 있으므로 0은 오히려 성능에 안 좋을 것이라 짐작)
- 모델
    - 변함 없음
- 결과
    - 일주일, 보름, 한 달 , 두 달, 세 달, 6개월의 거래내역 통계치 사용 및 imputing 0 사용한 결과 AUC 0.8301
    - 일주일, 보름, 한 달 , 두 달, 세 달, 6개월의 거래내역 통계치 사용 및 imputing -1 사용한 결과 AUC 0.8306
    - 일주일, 보름, 한 달 , 두 달, 세 달, 6개월의 거래내역 통계치 사용 및 imputing -1, threshold 310 사용한 결과 AUC 0.8306
    - 위 모델에서 전체 기간 거래내역 통계치 추가한 결과 AUC 0.8443



# Day 6
- 개요
    - 구매시간에 대한 feature 만들 필요 있음
    - 추가로 제공된 baseline 코드의 일부 적용, 응용 예정
    - 현재 fold의 수(10)가 많아서 낮추면 성능이 개선될 것이라 예상
- 데이터셋
    - 마지막 구매날짜를 수치형 데이터로 바꿔서 추가
    - 전체 기간 거래내역의 누적합을 추가
- 모델
    - 변함 없음
- 결과
    - 이전 날 최고 성능 상황에서 마지막 구매날짜 추가한 결과 AUC 0.8465
    - 이전 날 최고 성능 상황에서 마지막 구매날짜, 누적합 추가한 결과 AUC 0.8491
    - 이전 날 최고 성능 상황에서 마지막 구매날짜, 누적합 추가, threshold 330 적용한 결과 AUC 0.8487
    - 이전 날 최고 성능 상황에서 마지막 구매날짜, 누적합 추가, threshold 310, 5-fold 적용한 결과 AUC 0.8458



# Day 7
- 개요
    - 최근 기간 중 거래를 한 개월의 수가 유의미할 것이라 예상
    - 앞선 값과 거래를 한 달의 총 거래액의 평균도 유의미할 것이라 예상
    - 적용하지 않았던 baseline 코드 추가
    - 시계열 예측도 가능할 것이라 예상(https://dacon.io/competitions/official/140472/talkboard/400283?page=1&dtype=recent)
- 데이터셋
    - 최근 기간 중 거래한 개월 수 추가
    - 거래한 개월의 총 거래액 평균 추가
    - 거래한 개월의 총 거래액 평균을 범주형 변수로 변경
    - 거래 날짜 간 차이를 추가
    - 시계열 데이터 생성
- 모델
    - facebook에서 발표한 prophet을 사용
- 결과
    - 시계열 모델의 경우 예측에 3시간 소요됨
    - 시계열 모델의 결과를 직접 수기로 확인해본 결과 적용이 어렵다 판단
    - 최근 기간 중 거래한 개월 수, 거래액 평균, 거래액 평균의 범주형 변수 추가한 결과 AUC 0.8541
    - 앞선 상황에 거래 날짜 간 차이를 추가한 결과 AUC 0.8571
    - 앞선 상황에 전체 거래 내역을 사용중이었는데 이를 23개월치 거래내역으로 변경한 결과 AUC 0.8575
    - 앞선 상황에 max와 min의 차이, IQR을 추가한 결과 AUC 0.8579



# Day 8
- 개요
    - 코드 refactoring
    - AutoML 적용 예정
- 데이터셋
    - refactoring을 하면서 내부 코드 변경(중복되는 데이터가 존재함)
- 모델
    - 현재까지 중 제일 잘 나온 데이터를 기반으로 AutoML 적용
- 결과
    - refactoring한 데이터를 기반으로 한 결과 AUC 0.8564(오히려 떨어짐)
    - AutoML의 결과 AUC 0.7405
    - 전날 결과 재현이 안됨(refactoring 중 코드를 잘못 건드림)



# Day 9
- 개요
    - 현재까지 집착한 가정: 최근 일주일, 보름의 데이터가 특히 중요하므로 이 데이터에 민감하게 반응하는 것이 좋다
    - 현재까지 집착한 가정을 기반으로 feature 최대한 증폭
    - 현재까지 집착한 가정을 버리고 모델을 단순화
    - 앙상블
- 데이터셋
    - feature를 제곱, 로그를 이용하여 약 1만개의 feature 생성
    - 최근 일주일, 보름의 데이터가 아닌 모두 한 달 단위로 통계치 산출
    - 최근 일주일, 보름의 데이터가 아닌 모두 두 달 단위로 통계치 산출
    - 최근 일주일, 보름의 데이터가 아닌 모두 세 달 단위로 통계치 산출
- 모델
    - AutoML 기각
- 결과
    - feature 1만개 사용 결과 AUC 0.85 미만
    - 한 달 단위로 통계치 산출하여 적용한 결과 AUC 0.8603
    - 두 달 단위로 통계치 산출하여 적용한 결과 AUC 0.8606
    - 세 달 단위로 통계치 산출하여 적용한 결과와 앞선 두 결과를 앙상블 AUC 0.8629(최종제출)
