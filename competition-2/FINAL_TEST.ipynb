{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1dd079",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "369c07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, sys, gc, warnings, random\n",
    "\n",
    "import datetime\n",
    "import dateutil.relativedelta\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c856be",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c418579e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"/opt/ml/code/input/train.csv\", parse_dates=['order_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa8c5809",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4129b099",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def devide(x):\n",
    "    answer = ''\n",
    "    if x<0: answer = 'minus'\n",
    "    elif x<20: answer = 'very low'\n",
    "    elif x<40: answer = 'low'\n",
    "    elif x<70: answer = 'middle-low'\n",
    "    elif x<100: answer = 'middle'\n",
    "    elif x<150: answer = 'middle-high'\n",
    "    elif x<200: answer = 'almost'\n",
    "    elif x<250: answer = 'high'\n",
    "    elif x<270: answer = 'higgh'\n",
    "    elif x<300: answer = 'hiigh'\n",
    "    elif x<325: answer = 'veeery high'\n",
    "    elif x<350: answer = 'very high'\n",
    "    elif x<500: answer = 'very hiigh'\n",
    "    elif x<1000: answer = 'super high'\n",
    "    else: answer = 'epic high'\n",
    "    return answer\n",
    "\n",
    "def count_over(df,year_month):\n",
    "    cid = 'customer_id'\n",
    "    cust = df[df['year_month'] < year_month][cid].unique()\n",
    "    count = pd.DataFrame({'customer_id':cust}).sort_values(cid)\n",
    "    \n",
    "    count['count'] = 0\n",
    "    count = count.set_index(cid)\n",
    "    while True:\n",
    "        year_month = date(int(year_month.split('-')[0]),int(year_month.split('-')[1]),1) - dateutil.relativedelta.relativedelta(months=1)\n",
    "        year_month = year_month.strftime('%Y-%m')\n",
    "        total = df[df['year_month'] == year_month].groupby('customer_id').sum().reset_index()\n",
    "        if total.empty: break\n",
    "        cust = total[total['total']>300][cid].unique()\n",
    "        for x in cust:\n",
    "            count.at[x,'count']+=1\n",
    "    return count.sort_values('customer_id').reset_index()['count']\n",
    "\n",
    "def mean_during_usage(df, year_month):\n",
    "    df = df.copy()\n",
    "    cid = 'customer_id'\n",
    "    cust = df[df['year_month'] < year_month][cid].unique()\n",
    "    count = pd.DataFrame({'customer_id':cust}).sort_values(cid)\n",
    "    \n",
    "    count['count'] = 0\n",
    "    count = count.set_index(cid)\n",
    "    while True:\n",
    "        year_month = date(int(year_month.split('-')[0]),int(year_month.split('-')[1]),1) - dateutil.relativedelta.relativedelta(months=1)\n",
    "        year_month = year_month.strftime('%Y-%m')\n",
    "        total = df[df['year_month'] == year_month].groupby('customer_id').sum().reset_index()\n",
    "        if total.empty: break\n",
    "        cust = total[total['total']>300][cid].unique()\n",
    "        for x in cust:\n",
    "            count.at[x,'count']+=1\n",
    "    return count.sort_values('customer_id').reset_index()['count']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec619856",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOTAL_THRES = 300\n",
    "\n",
    "'''\n",
    "    입력인자로 받는 year_month에 대해 고객 ID별로 총 구매액이\n",
    "    구매액 임계값을 넘는지 여부의 binary label을 생성하는 함수\n",
    "'''\n",
    "def generate_label(df, year_month, total_thres=TOTAL_THRES, print_log=False):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # year_month에 해당하는 label 데이터 생성\n",
    "    df['year_month'] = df['order_date'].dt.strftime('%Y-%m')\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # year_month 이전 월의 고객 ID 추출\n",
    "    cust = df[df['year_month']<year_month]['customer_id'].unique()\n",
    "    # year_month에 해당하는 데이터 선택\n",
    "    df = df[df['year_month']==year_month]\n",
    "    \n",
    "    # label 데이터프레임 생성\n",
    "    label = pd.DataFrame({'customer_id':cust})\n",
    "    label['year_month'] = year_month\n",
    "    \n",
    "    # year_month에 해당하는 고객 ID의 구매액의 합 계산\n",
    "    grped = df.groupby(['customer_id','year_month'], as_index=False)[['total']].sum()\n",
    "    \n",
    "    # label 데이터프레임과 merge하고 구매액 임계값을 넘었는지 여부로 label 생성\n",
    "    label = label.merge(grped, on=['customer_id','year_month'], how='left')\n",
    "    label['total'].fillna(0.0, inplace=True)\n",
    "    label['label'] = (label['total'] > total_thres).astype(int)\n",
    "\n",
    "    # 고객 ID로 정렬\n",
    "    label = label.sort_values('customer_id').reset_index(drop=True)\n",
    "    if print_log: print(f'{year_month} - final label shape: {label.shape}')\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "313a5179",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def feature_preprocessing(train, test, features, do_imputing=True):\n",
    "    x_tr = train.copy()\n",
    "    x_te = test.copy()\n",
    "    \n",
    "    # 범주형 피처 이름을 저장할 변수\n",
    "    cate_cols = []\n",
    "\n",
    "    # 레이블 인코딩\n",
    "    for f in features:\n",
    "        if x_tr[f].dtype.name == 'object': # 데이터 타입이 object(str)이면 레이블 인코딩\n",
    "            cate_cols.append(f)\n",
    "            le = LabelEncoder()\n",
    "            # train + test 데이터를 합쳐서 레이블 인코딩 함수에 fit\n",
    "            le.fit(list(x_tr[f].values) + list(x_te[f].values))\n",
    "            \n",
    "            # train 데이터 레이블 인코딩 변환 수행\n",
    "            x_tr[f] = le.transform(list(x_tr[f].values))\n",
    "            \n",
    "            # test 데이터 레이블 인코딩 변환 수행\n",
    "            x_te[f] = le.transform(list(x_te[f].values))\n",
    "\n",
    "    print('categorical feature:', cate_cols)\n",
    "    \n",
    "    if do_imputing:\n",
    "        impt = SimpleImputer(strategy='constant', fill_value=-2)\n",
    "        x_tr[features] = impt.fit_transform(x_tr[features])\n",
    "        x_te[features] = impt.transform(x_te[features])\n",
    "    \n",
    "    return x_tr, x_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15ea8c31",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_feature(df, ref_date, period, feature, col_prefix):\n",
    "    df = df.copy()\n",
    "    ref_date = datetime.datetime.strptime(ref_date, \"%Y-%m\")\n",
    "    if period[0]=='d':\n",
    "        # period[1] > period[2]\n",
    "        date_s = ref_date - dateutil.relativedelta.relativedelta(days=period[1])\n",
    "        date_e = ref_date - dateutil.relativedelta.relativedelta(days=period[2])\n",
    "    if period[0]=='m':\n",
    "        # period[1] > period[2]\n",
    "        date_s = ref_date - dateutil.relativedelta.relativedelta(months=period[1])\n",
    "        date_e = ref_date - dateutil.relativedelta.relativedelta(months=period[2])\n",
    "    date_s = date_s.strftime(\"%Y-%m-%d\")\n",
    "    date_e = date_e.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    df = df[(date_s<df['order_date'])&(date_e>df['order_date'])]\n",
    "\n",
    "    # customer_id 기준으로 pandas group by 후 total, quantity, price 누적합 계산\n",
    "    df['cumsum_total_by_cust_id'] = df.groupby(['customer_id'])['total'].cumsum()\n",
    "    df['cumsum_quantity_by_cust_id'] = df.groupby(['customer_id'])['quantity'].cumsum()\n",
    "    df['cumsum_price_by_cust_id'] = df.groupby(['customer_id'])['price'].cumsum()\n",
    "\n",
    "    # product_id 기준으로 pandas group by 후 total, quantity, price 누적합 계산\n",
    "    df['cumsum_total_by_prod_id'] = df.groupby(['product_id'])['total'].cumsum()\n",
    "    df['cumsum_quantity_by_prod_id'] = df.groupby(['product_id'])['quantity'].cumsum()\n",
    "    df['cumsum_price_by_prod_id'] = df.groupby(['product_id'])['price'].cumsum()\n",
    "    \n",
    "    # order_id 기준으로 pandas group by 후 total, quantity, price 누적합 계산\n",
    "    df['cumsum_total_by_order_id'] = df.groupby(['order_id'])['total'].cumsum()\n",
    "    df['cumsum_quantity_by_order_id'] = df.groupby(['order_id'])['quantity'].cumsum()\n",
    "    df['cumsum_price_by_order_id'] = df.groupby(['order_id'])['price'].cumsum()\n",
    "\n",
    "    # new baseline\n",
    "    df['order_ts'] = df['order_date'].astype(np.int64)//1e9\n",
    "    df['order_ts_diff'] = df.groupby(['customer_id'])['order_ts'].diff()\n",
    "    df['quantity_diff'] = df.groupby(['customer_id'])['quantity'].diff()\n",
    "    df['price_diff'] = df.groupby(['customer_id'])['price'].diff()\n",
    "    df['total_diff'] = df.groupby(['customer_id'])['total'].diff()\n",
    "    \n",
    "    ret_data = pd.DataFrame()\n",
    "    \n",
    "    # group by aggretation 함수로 데이터 피처 생성\n",
    "    df_agg = df.groupby(['customer_id']).agg(feature)\n",
    "\n",
    "    # 멀티 레벨 컬럼을 사용하기 쉽게 1 레벨 컬럼명으로 변경\n",
    "    new_cols = []\n",
    "    cnt = 0\n",
    "    for col in feature.keys():\n",
    "        for stat in feature[col]:\n",
    "            if type(stat) is str:\n",
    "                new_cols.append(f'{col_prefix}-{col}-{stat}')\n",
    "            else:\n",
    "                new_cols.append(f'{col_prefix}-{col}-custom_{cnt}')\n",
    "                cnt += 1\n",
    "            \n",
    "\n",
    "    df_agg.columns = new_cols\n",
    "    df_agg.reset_index(inplace = True)\n",
    "\n",
    "    df_agg['year_month'] = ref_date\n",
    "    df_agg['year_month'] = df_agg['year_month'].dt.strftime('%Y-%m')\n",
    "\n",
    "    ret_data = ret_data.append(df_agg)\n",
    "    \n",
    "    # ret_data = train_label.merge(all_train_data, on=['customer_id', 'year_month'], how='left')\n",
    "    features = ret_data.drop(columns=['customer_id', 'year_month']).columns\n",
    "    \n",
    "    # ret_data 데이터 전처리 -> 수정 후 나중에 해도 될 듯?\n",
    "    # x_tr, x_te = feature_preprocessing(all_train_data, test_data, features)\n",
    "    \n",
    "    print('ret_data.shape', ret_data.shape)\n",
    "    \n",
    "    return ret_data, features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07fdfca2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_fixed_period_feature(df, ref_date, period, feature, col_prefix):\n",
    "    df = df.copy()\n",
    "    date_s = period[0]\n",
    "    date_e = period[1]\n",
    "    \n",
    "    df = df[(date_s<df['order_date'])&(date_e>df['order_date'])]\n",
    "\n",
    "    # customer_id 기준으로 pandas group by 후 total, quantity, price 누적합 계산\n",
    "    df['cumsum_total_by_cust_id'] = df.groupby(['customer_id'])['total'].cumsum()\n",
    "    df['cumsum_quantity_by_cust_id'] = df.groupby(['customer_id'])['quantity'].cumsum()\n",
    "    df['cumsum_price_by_cust_id'] = df.groupby(['customer_id'])['price'].cumsum()\n",
    "\n",
    "    # product_id 기준으로 pandas group by 후 total, quantity, price 누적합 계산\n",
    "    df['cumsum_total_by_prod_id'] = df.groupby(['product_id'])['total'].cumsum()\n",
    "    df['cumsum_quantity_by_prod_id'] = df.groupby(['product_id'])['quantity'].cumsum()\n",
    "    df['cumsum_price_by_prod_id'] = df.groupby(['product_id'])['price'].cumsum()\n",
    "    \n",
    "    # order_id 기준으로 pandas group by 후 total, quantity, price 누적합 계산\n",
    "    df['cumsum_total_by_order_id'] = df.groupby(['order_id'])['total'].cumsum()\n",
    "    df['cumsum_quantity_by_order_id'] = df.groupby(['order_id'])['quantity'].cumsum()\n",
    "    df['cumsum_price_by_order_id'] = df.groupby(['order_id'])['price'].cumsum()\n",
    "\n",
    "    # new baseline\n",
    "    df['order_ts'] = df['order_date'].astype(np.int64)//1e9\n",
    "    df['order_ts_diff'] = df.groupby(['customer_id'])['order_ts'].diff()\n",
    "    df['quantity_diff'] = df.groupby(['customer_id'])['quantity'].diff()\n",
    "    df['price_diff'] = df.groupby(['customer_id'])['price'].diff()\n",
    "    df['total_diff'] = df.groupby(['customer_id'])['total'].diff()\n",
    "    \n",
    "    ret_data = pd.DataFrame()\n",
    "    \n",
    "    # group by aggretation 함수로 데이터 피처 생성\n",
    "    df_agg = df.groupby(['customer_id']).agg(feature)\n",
    "\n",
    "    # 멀티 레벨 컬럼을 사용하기 쉽게 1 레벨 컬럼명으로 변경\n",
    "    new_cols = []\n",
    "    cnt = 0\n",
    "    for col in feature.keys():\n",
    "        for stat in feature[col]:\n",
    "            if type(stat) is str:\n",
    "                new_cols.append(f'{col_prefix}-{col}-{stat}')\n",
    "            else:\n",
    "                new_cols.append(f'{col_prefix}-{col}-custom_{cnt}')\n",
    "                cnt += 1\n",
    "            \n",
    "\n",
    "    df_agg.columns = new_cols\n",
    "    df_agg.reset_index(inplace = True)\n",
    "\n",
    "    df_agg['year_month'] = datetime.datetime.strptime(ref_date, \"%Y-%m\")\n",
    "    df_agg['year_month'] = df_agg['year_month'].dt.strftime('%Y-%m')\n",
    "\n",
    "    ret_data = ret_data.append(df_agg)\n",
    "    \n",
    "    # ret_data = train_label.merge(all_train_data, on=['customer_id', 'year_month'], how='left')\n",
    "    features = ret_data.drop(columns=['customer_id', 'year_month']).columns\n",
    "    \n",
    "    # ret_data 데이터 전처리 -> 수정 후 나중에 해도 될 듯?\n",
    "    # x_tr, x_te = feature_preprocessing(all_train_data, test_data, features)\n",
    "    \n",
    "    print('ret_data.shape', ret_data.shape)\n",
    "    \n",
    "    return ret_data, features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efe278ed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def range_func(x):\n",
    "    max_val = np.max(x)\n",
    "    min_val = np.min(x)\n",
    "    range_val = max_val - min_val\n",
    "    return range_val\n",
    "\n",
    "\n",
    "def iqr_func(x):\n",
    "    q3, q1 = np.percentile(x, [75, 25])\n",
    "    iqr = q3 - q1\n",
    "    return iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "679e8030",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering3(df, test_ref_date, train_ref_date, period_rule, feature_rule, total_thres):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. customer_id 추출\n",
    "    train_label = generate_label(df, train_ref_date, total_thres)[['customer_id','year_month','label']]\n",
    "    test_label = generate_label(df, test_ref_date, total_thres)[['customer_id','year_month','label']]\n",
    "    \n",
    "    # 2. period_rule과 feature_rule에 따라서 위 customer_id에 대응하는 값을 train_ref_date에서 추출\n",
    "    # 3. 2에서 추출한 dataframe을 병합하여 train_data\n",
    "    train_data = train_label.copy()\n",
    "    # train_df_list = []\n",
    "    train_feat_list = None\n",
    "    if len(period_rule)!=len(feature_rule):\n",
    "        raise(\"Error:\\n\\tlen(period_rule)!=len(feature_rule)\")\n",
    "    for i in range(len(period_rule)):\n",
    "        res_tuple = make_feature(df, train_ref_date, period_rule[i], feature_rule[i], i)\n",
    "        train_data = train_data.merge(res_tuple[0], on=['customer_id', 'year_month'], how='left')\n",
    "        if train_feat_list is None:\n",
    "            train_feat_list = res_tuple[1].copy()\n",
    "        else:\n",
    "            train_feat_list = train_feat_list.append(res_tuple[1].copy())\n",
    "    \n",
    "    df['year_month'] = [str(x)[:7] for x in df['order_date'].copy()[:]]\n",
    "    train = df[(df['year_month']<'2011-11')&(df['year_month']>'2011-01')][:]\n",
    "    train_month_count = [len(set(train[train['customer_id']==cust]['year_month'])) for cust in train_data['customer_id'].copy()]\n",
    "    train_month_sum = [train[train['customer_id']==cust]['total'].sum() for cust in train_data['customer_id'].copy()]\n",
    "    train_month_mean = [y/x if x>0 else 0 for x, y in zip(train_month_count, train_month_sum)]\n",
    "    train_mean_cat = [devide(x) for x in train_month_mean]\n",
    "    train_data['count_m'] = train_month_count\n",
    "    train_data['sum_m'] = train_month_sum\n",
    "    train_data['mean_m'] = train_month_mean\n",
    "    train_data['mean_cat'] = train_mean_cat\n",
    "    train_feat_list = train_feat_list.append(pd.Index(['count_m', 'sum_m', 'mean_m', 'mean_cat']))\n",
    "\n",
    "    \n",
    "    # 4. period_rule과 feature_rule에 따라서 위 customer_id에 대응하는 값을 test_ref_date에서 추출\n",
    "    # 5. 4에서 추출한 dataframe을 병합하여 test_data\n",
    "    test_data = test_label.copy()\n",
    "    # test_df_list = []\n",
    "    test_feat_list = None\n",
    "    for i in range(len(period_rule)):\n",
    "        res_tuple = make_feature(df, test_ref_date, period_rule[i], feature_rule[i], i)\n",
    "        test_data = test_data.merge(res_tuple[0], on=['customer_id', 'year_month'], how='left')\n",
    "        if test_feat_list is None:\n",
    "            test_feat_list = res_tuple[1].copy()\n",
    "        else:\n",
    "            test_feat_list = test_feat_list.append(res_tuple[1].copy())\n",
    "    \n",
    "    test = df[(df['year_month']<'2011-12')&(df['year_month']>'2011-02')][:]\n",
    "    test_month_count = [len(set(test[test['customer_id']==cust]['year_month'])) for cust in test_data['customer_id'].copy()]\n",
    "    test_month_sum = [test[test['customer_id']==cust]['total'].sum() for cust in test_data['customer_id'].copy()]\n",
    "    test_month_mean = [y/x if x>0 else 0 for x, y in zip(test_month_count, test_month_sum)]\n",
    "    test_mean_cat = [devide(x) for x in test_month_mean]\n",
    "    test_data['count_m'] = test_month_count\n",
    "    test_data['sum_m'] = test_month_sum\n",
    "    test_data['mean_m'] = test_month_mean\n",
    "    test_data['mean_cat'] = test_mean_cat\n",
    "    test_feat_list = test_feat_list.append(pd.Index(['count_m', 'sum_m', 'mean_m', 'mean_cat']))\n",
    "    \n",
    "    # train_feat_list = train_data.drop(columns=['customer_id', 'label', 'year_month']).columns # 한번 해봄\n",
    "    \n",
    "    # 6. train_data, train_label, test_data, test_label, features 최종 반환\n",
    "    if (train_feat_list!=test_feat_list).sum()!=0: # len(train_feat_list)!=len(test_feat_list)\n",
    "        raise(\"Error:\\n\\t(train_feat_list!=test_feat_list).sum()!=0\")\n",
    "    x_tr, x_te = feature_preprocessing(train_data, test_data, train_feat_list, do_imputing=True)\n",
    "    \n",
    "    print('x_tr.shape', x_tr.shape, ', x_te.shape', x_te.shape)\n",
    "    \n",
    "    return x_tr, x_te, train_label['label'], train_feat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50bb7197",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_anything(df, features):\n",
    "    df = df.copy()\n",
    "    for f in features:\n",
    "        if not pd.api.types.is_numeric_dtype(df[f]):\n",
    "            continue\n",
    "        if f=='mean_cat':\n",
    "            continue\n",
    "        new_colname = f+\"_squared_n_log\"\n",
    "        df[new_colname] = [x*2 for x in df[f]]\n",
    "        df[new_colname] = [np.log(x+0.5) for x in df[new_colname]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88018499",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "agg_basic = ['mean','max','min','sum','count','std','skew']\n",
    "agg_custom = ['mean','max','min','sum','count','std','skew', 'median', range_func, iqr_func]\n",
    "agg_custom_2 = ['mean','max','min','sum','count','std','skew', 'median', range_func]\n",
    "agg_dict = {\n",
    "    'quantity': agg_custom,\n",
    "    'price': agg_custom,\n",
    "    'total': agg_custom,\n",
    "    'cumsum_total_by_cust_id': agg_custom,\n",
    "    'cumsum_quantity_by_cust_id': agg_custom,\n",
    "    'cumsum_price_by_cust_id': agg_custom,\n",
    "    'cumsum_total_by_prod_id': agg_custom,\n",
    "    'cumsum_quantity_by_prod_id': agg_custom,\n",
    "    'cumsum_price_by_prod_id': agg_custom,\n",
    "    'cumsum_total_by_order_id': agg_custom,\n",
    "    'cumsum_quantity_by_order_id': agg_custom,\n",
    "    'cumsum_price_by_order_id': agg_custom,\n",
    "    'order_id': ['nunique'],\n",
    "    'product_id': ['nunique'],\n",
    "    \"order_ts\":[\"first\", \"last\"],\n",
    "    \"order_ts_diff\":agg_custom_2,\n",
    "    \"quantity_diff\":agg_custom_2,\n",
    "    \"price_diff\":agg_custom_2,\n",
    "    \"total_diff\":agg_custom_2\n",
    "}\n",
    "\n",
    "\n",
    "def feature_engineering4(df, test_ref_date, train_ref_date, period_rule, feature_rule, total_thres):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. customer_id 추출\n",
    "    train_label = generate_label(df, train_ref_date, total_thres)[['customer_id','year_month','label']]\n",
    "    test_label = generate_label(df, test_ref_date, total_thres)[['customer_id','year_month','label']]\n",
    "    \n",
    "    # 2. period_rule과 feature_rule에 따라서 위 customer_id에 대응하는 값을 train_ref_date에서 추출\n",
    "    # 3. 2에서 추출한 dataframe을 병합하여 train_data\n",
    "    train_data = train_label.copy()\n",
    "    # train_df_list = []\n",
    "    train_feat_list = None\n",
    "    if len(period_rule)!=len(feature_rule):\n",
    "        raise(\"Error:\\n\\tlen(period_rule)!=len(feature_rule)\")\n",
    "    for i in range(len(period_rule)):\n",
    "        res_tuple = make_feature(df, train_ref_date, period_rule[i], feature_rule[i], i)\n",
    "        train_data = train_data.merge(res_tuple[0], on=['customer_id', 'year_month'], how='left')\n",
    "        if train_feat_list is None:\n",
    "            train_feat_list = res_tuple[1].copy()\n",
    "        else:\n",
    "            train_feat_list = train_feat_list.append(res_tuple[1].copy())\n",
    "    #res_tuple = make_fixed_period_feature(df, train_ref_date, (\"2010-11\", \"2011-11\"), agg_dict, len(period_rule))\n",
    "    #train_data = train_data.merge(res_tuple[0], on=['customer_id', 'year_month'], how='left')\n",
    "    #train_feat_list = train_feat_list.append(res_tuple[1].copy())\n",
    "    \n",
    "    \n",
    "    df['year_month'] = [str(x)[:7] for x in df['order_date'].copy()[:]]\n",
    "    train = df[(df['year_month']<'2011-11')&(df['year_month']>'2010-12')][:]\n",
    "    train_month_count = [len(set(train[train['customer_id']==cust]['year_month'])) for cust in train_data['customer_id'].copy()]\n",
    "    train_month_sum = [train[train['customer_id']==cust]['total'].sum() for cust in train_data['customer_id'].copy()]\n",
    "    train_month_mean = [y/x if x>0 else 0 for x, y in zip(train_month_count, train_month_sum)]\n",
    "    train_mean_cat = [devide(x) for x in train_month_mean]\n",
    "    train_data['count_m'] = train_month_count\n",
    "    train_data['sum_m'] = train_month_sum\n",
    "    train_data['mean_m'] = train_month_mean\n",
    "    train_data['mean_cat'] = train_mean_cat\n",
    "    train_feat_list = train_feat_list.append(pd.Index(['count_m', 'sum_m', 'mean_m', 'mean_cat']))\n",
    "\n",
    "    \n",
    "    # 4. period_rule과 feature_rule에 따라서 위 customer_id에 대응하는 값을 test_ref_date에서 추출\n",
    "    # 5. 4에서 추출한 dataframe을 병합하여 test_data\n",
    "    test_data = test_label.copy()\n",
    "    # test_df_list = []\n",
    "    test_feat_list = None\n",
    "    for i in range(len(period_rule)):\n",
    "        res_tuple = make_feature(df, test_ref_date, period_rule[i], feature_rule[i], i)\n",
    "        test_data = test_data.merge(res_tuple[0], on=['customer_id', 'year_month'], how='left')\n",
    "        if test_feat_list is None:\n",
    "            test_feat_list = res_tuple[1].copy()\n",
    "        else:\n",
    "            test_feat_list = test_feat_list.append(res_tuple[1].copy())\n",
    "    #res_tuple = make_fixed_period_feature(df, test_ref_date, (\"2010-11\", \"2011-11\"), agg_dict, len(period_rule))\n",
    "    #test_data = test_data.merge(res_tuple[0], on=['customer_id', 'year_month'], how='left')\n",
    "    #test_feat_list = test_feat_list.append(res_tuple[1].copy())\n",
    "    \n",
    "    test = df[(df['year_month']<'2011-12')&(df['year_month']>'2011-01')][:]\n",
    "    test_month_count = [len(set(test[test['customer_id']==cust]['year_month'])) for cust in test_data['customer_id'].copy()]\n",
    "    test_month_sum = [test[test['customer_id']==cust]['total'].sum() for cust in test_data['customer_id'].copy()]\n",
    "    test_month_mean = [y/x if x>0 else 0 for x, y in zip(test_month_count, test_month_sum)]\n",
    "    test_mean_cat = [devide(x) for x in test_month_mean]\n",
    "    test_data['count_m'] = test_month_count\n",
    "    test_data['sum_m'] = test_month_sum\n",
    "    test_data['mean_m'] = test_month_mean\n",
    "    test_data['mean_cat'] = test_mean_cat\n",
    "    test_feat_list = test_feat_list.append(pd.Index(['count_m', 'sum_m', 'mean_m', 'mean_cat']))\n",
    "    \n",
    "    train_feat_list = train_data.drop(columns=['customer_id', 'label', 'year_month']).columns # 한번 해봄\n",
    "    test_feat_list = test_data.drop(columns=['customer_id', 'label', 'year_month']).columns\n",
    "    \n",
    "    # 6. train_data, train_label, test_data, test_label, features 최종 반환\n",
    "    if (train_feat_list!=test_feat_list).sum()!=0: # len(train_feat_list)!=len(test_feat_list)\n",
    "        raise(\"Error:\\n\\t(train_feat_list!=test_feat_list).sum()!=0\")\n",
    "    x_tr, x_te = feature_preprocessing(train_data, test_data, train_feat_list, do_imputing=True)\n",
    "    \n",
    "    # x_tr = do_anything(x_tr, train_feat_list)\n",
    "    # x_te = do_anything(x_te, train_feat_list)\n",
    "    # train_feat_list = x_tr.drop(columns=['customer_id', 'label', 'year_month']).columns\n",
    "    \n",
    "    print('x_tr.shape', x_tr.shape, ', x_te.shape', x_te.shape)\n",
    "    \n",
    "    return x_tr, x_te, train_label['label'], train_feat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82879924",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_lgb_oof_prediction(train, y, test, features, categorical_features='auto', model_params=None, folds=10):\n",
    "    x_train = train[features]\n",
    "    x_test = test[features]\n",
    "    \n",
    "    # 테스트 데이터 예측값을 저장할 변수\n",
    "    test_preds = np.zeros(x_test.shape[0])\n",
    "    \n",
    "    # Out Of Fold Validation 예측 데이터를 저장할 변수\n",
    "    y_oof = np.zeros(x_train.shape[0])\n",
    "    \n",
    "    # 폴드별 평균 Validation 스코어를 저장할 변수\n",
    "    score = 0\n",
    "    \n",
    "    # 피처 중요도를 저장할 데이터 프레임 선언\n",
    "    fi = pd.DataFrame()\n",
    "    fi['feature'] = features\n",
    "    \n",
    "    # Stratified K Fold 선언\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(x_train, y)):\n",
    "        # train index, validation index로 train 데이터를 나눔\n",
    "        x_tr, x_val = x_train.loc[tr_idx, features], x_train.loc[val_idx, features]\n",
    "        y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "        \n",
    "        print(f'fold: {fold+1}, x_tr.shape: {x_tr.shape}, x_val.shape: {x_val.shape}')\n",
    "\n",
    "        # LightGBM 데이터셋 선언\n",
    "        dtrain = lgb.Dataset(x_tr, label=y_tr)\n",
    "        dvalid = lgb.Dataset(x_val, label=y_val)\n",
    "        \n",
    "        # LightGBM 모델 훈련\n",
    "        clf = lgb.train(\n",
    "            model_params,\n",
    "            dtrain,\n",
    "            valid_sets=[dtrain, dvalid], # Validation 성능을 측정할 수 있도록 설정\n",
    "            categorical_feature=categorical_features,\n",
    "            verbose_eval=200\n",
    "        )\n",
    "\n",
    "        # Validation 데이터 예측\n",
    "        val_preds = clf.predict(x_val)\n",
    "        \n",
    "        # Validation index에 예측값 저장 \n",
    "        y_oof[val_idx] = val_preds\n",
    "        \n",
    "        # 폴드별 Validation 스코어 측정\n",
    "        print(f\"Fold {fold + 1} | AUC: {roc_auc_score(y_val, val_preds)}\")\n",
    "        print('-'*80)\n",
    "\n",
    "        # score 변수에 폴드별 평균 Validation 스코어 저장\n",
    "        score += roc_auc_score(y_val, val_preds) / folds\n",
    "        \n",
    "        # 테스트 데이터 예측하고 평균해서 저장\n",
    "        test_preds += clf.predict(x_test) / folds\n",
    "        \n",
    "        # 폴드별 피처 중요도 저장\n",
    "        fi[f'fold_{fold+1}'] = clf.feature_importance()\n",
    "\n",
    "        del x_tr, x_val, y_tr, y_val\n",
    "        gc.collect()\n",
    "        \n",
    "    print(f\"\\nMean AUC = {score}\") # 폴드별 Validation 스코어 출력\n",
    "    print(f\"OOF AUC = {roc_auc_score(y, y_oof)}\") # Out Of Fold Validation 스코어 출력\n",
    "        \n",
    "    # 폴드별 피처 중요도 평균값 계산해서 저장 \n",
    "    fi_cols = [col for col in fi.columns if 'fold_' in col]\n",
    "    fi['importance'] = fi[fi_cols].mean(axis=1)\n",
    "    \n",
    "    return y_oof, test_preds, fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964af5c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe66737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_basic = ['mean','max','min','sum','count','std','skew']\n",
    "agg_custom = ['mean','max','min','sum','count','std','skew', 'median', range_func, iqr_func]\n",
    "agg_custom_2 = ['mean','max','min','sum','count','std','skew', 'median', range_func]\n",
    "agg_dict = {\n",
    "    'quantity': agg_custom,\n",
    "    'price': agg_custom,\n",
    "    'total': agg_custom,\n",
    "    'cumsum_total_by_cust_id': agg_custom,\n",
    "    'cumsum_quantity_by_cust_id': agg_custom,\n",
    "    'cumsum_price_by_cust_id': agg_custom,\n",
    "    'cumsum_total_by_prod_id': agg_custom,\n",
    "    'cumsum_quantity_by_prod_id': agg_custom,\n",
    "    'cumsum_price_by_prod_id': agg_custom,\n",
    "    'cumsum_total_by_order_id': agg_custom,\n",
    "    'cumsum_quantity_by_order_id': agg_custom,\n",
    "    'cumsum_price_by_order_id': agg_custom,\n",
    "    'order_id': ['nunique'],\n",
    "    'product_id': ['nunique'],\n",
    "    \"order_ts\":[\"first\", \"last\"],\n",
    "    \"order_ts_diff\":agg_custom_2,\n",
    "    \"quantity_diff\":agg_custom_2,\n",
    "    \"price_diff\":agg_custom_2,\n",
    "    \"total_diff\":agg_custom_2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bb39bd",
   "metadata": {},
   "source": [
    "## trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19fa89df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline model: baseline3\n",
      "ret_data.shape (455, 162)\n",
      "ret_data.shape (408, 162)\n",
      "ret_data.shape (858, 162)\n",
      "ret_data.shape (1302, 162)\n",
      "ret_data.shape (980, 162)\n",
      "ret_data.shape (2064, 162)\n",
      "ret_data.shape (3234, 162)\n",
      "ret_data.shape (1906, 162)\n",
      "ret_data.shape (2281, 162)\n",
      "ret_data.shape (2560, 162)\n",
      "ret_data.shape (5620, 162)\n",
      "ret_data.shape (512, 162)\n",
      "ret_data.shape (614, 162)\n",
      "ret_data.shape (1112, 162)\n",
      "ret_data.shape (1425, 162)\n",
      "ret_data.shape (1302, 162)\n",
      "ret_data.shape (1993, 162)\n",
      "ret_data.shape (3499, 162)\n",
      "ret_data.shape (2027, 162)\n",
      "ret_data.shape (1749, 162)\n",
      "ret_data.shape (2936, 162)\n",
      "ret_data.shape (5750, 162)\n",
      "categorical feature: ['mean_cat']\n",
      "x_tr.shape (5722, 1767) , x_te.shape (5914, 1767)\n",
      "train type: <class 'pandas.core.frame.DataFrame'>\n",
      "test type: <class 'pandas.core.frame.DataFrame'>\n",
      "y type: <class 'pandas.core.series.Series'>\n",
      "features type: <class 'pandas.core.indexes.base.Index'>\n"
     ]
    }
   ],
   "source": [
    "model = 'baseline3'\n",
    "print('baseline model:', model)\n",
    "\n",
    "\n",
    "TOTAL_THRES = 300 # 구매액 임계값\n",
    "SEED = 42 # 랜덤 시드\n",
    "seed_everything(SEED) # 시드 고정\n",
    "\n",
    "\n",
    "data_dir = './input'\n",
    "model_dir = './model'\n",
    "output_dir = './output'\n",
    "\n",
    "\n",
    "# 데이터 파일 읽기\n",
    "data = pd.read_csv(data_dir + '/train.csv', parse_dates=['order_date'])\n",
    "\n",
    "# 예측할 연월 설정\n",
    "year_month = '2011-12'\n",
    "\n",
    "\n",
    "period_rule = [(\"d\", 7, 0), (\"d\", 14, 7), (\"d\", 30, 14), (\"m\", 2, 1), (\"m\", 3, 2), (\"m\", 6, 3), (\"m\", 6, 0), (\"m\", 9, 6), (\"m\", 12, 9), (\"m\", 15, 12), ('m', 22, 0)]\n",
    "feature_rule = [\n",
    "    agg_dict for _ in range(len(period_rule))\n",
    "]\n",
    "\n",
    "\n",
    "# 피처 엔지니어링 실행\n",
    "train, test, y, features = feature_engineering4(data, year_month, '2011-11', period_rule, feature_rule, 300)\n",
    "\n",
    "\n",
    "print(f\"train type: {type(train)}\")\n",
    "print(f\"test type: {type(test)}\")\n",
    "print(f\"y type: {type(y)}\")\n",
    "print(f\"features type: {type(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35e2d64b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, x_tr.shape: (5149, 1764), x_val.shape: (573, 1764)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999636\tvalid_1's auc: 0.803687\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.968537\tvalid_1's auc: 0.811572\n",
      "Fold 1 | AUC: 0.811572205974901\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 2, x_tr.shape: (5149, 1764), x_val.shape: (573, 1764)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999598\tvalid_1's auc: 0.79334\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.885821\tvalid_1's auc: 0.823233\n",
      "Fold 2 | AUC: 0.8232332580609337\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 3, x_tr.shape: (5150, 1764), x_val.shape: (572, 1764)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.99961\tvalid_1's auc: 0.808482\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.926319\tvalid_1's auc: 0.831031\n",
      "Fold 3 | AUC: 0.8310311356678861\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 4, x_tr.shape: (5150, 1764), x_val.shape: (572, 1764)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999598\tvalid_1's auc: 0.807735\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's auc: 0.92291\tvalid_1's auc: 0.830424\n",
      "Fold 4 | AUC: 0.8304244754722615\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 5, x_tr.shape: (5150, 1764), x_val.shape: (572, 1764)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999454\tvalid_1's auc: 0.792123\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's auc: 0.94721\tvalid_1's auc: 0.812919\n",
      "Fold 5 | AUC: 0.8129185449014041\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 6, x_tr.shape: (5150, 1764), x_val.shape: (572, 1764)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999593\tvalid_1's auc: 0.827314\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.938299\tvalid_1's auc: 0.842766\n",
      "Fold 6 | AUC: 0.842766245571076\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 7, x_tr.shape: (5150, 1764), x_val.shape: (572, 1764)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999616\tvalid_1's auc: 0.780724\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.955782\tvalid_1's auc: 0.797642\n",
      "Fold 7 | AUC: 0.797642235702228\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 8, x_tr.shape: (5150, 1764), x_val.shape: (572, 1764)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999626\tvalid_1's auc: 0.803124\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.896944\tvalid_1's auc: 0.812464\n",
      "Fold 8 | AUC: 0.8124640584710706\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 9, x_tr.shape: (5150, 1764), x_val.shape: (572, 1764)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.99959\tvalid_1's auc: 0.826961\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.951397\tvalid_1's auc: 0.841857\n",
      "Fold 9 | AUC: 0.8418572727104086\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 10, x_tr.shape: (5150, 1764), x_val.shape: (572, 1764)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999543\tvalid_1's auc: 0.799859\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.911112\tvalid_1's auc: 0.83593\n",
      "Fold 10 | AUC: 0.8359303986495259\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Mean AUC = 0.8239839831181697\n",
      "OOF AUC = 0.8130828576902684\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    'objective': 'binary', # 이진 분류\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'auc', # 평가 지표 설정\n",
    "    'feature_fraction': 0.7, # 피처 샘플링 비율\n",
    "    'bagging_fraction': 0.6, # 데이터 샘플링 비율\n",
    "    'bagging_freq': 1,\n",
    "    'n_estimators': 10000, # 트리 개수\n",
    "    'early_stopping_rounds': 300,\n",
    "    'seed': SEED,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "}\n",
    "\n",
    "\n",
    "# Cross Validation Out Of Fold로 LightGBM 모델 훈련 및 예측\n",
    "y_oof, test_preds, fi = make_lgb_oof_prediction(train, y, test, features, model_params=model_params, folds=10)\n",
    "\n",
    "# 테스트 결과 제출 파일 읽기\n",
    "sub = pd.read_csv('./input/sample_submission.csv')\n",
    "\n",
    "# 테스트 예측 결과 저장\n",
    "sub['probability'] = test_preds\n",
    "\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# 제출 파일 쓰기\n",
    "sub.to_csv(os.path.join('output_baseline3_final_1.csv'), index=False)\n",
    "# 기존 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8419c2",
   "metadata": {},
   "source": [
    "## trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddb716bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline model: baseline3\n",
      "ret_data.shape (1425, 162)\n",
      "ret_data.shape (1302, 162)\n",
      "ret_data.shape (980, 162)\n",
      "ret_data.shape (2064, 162)\n",
      "ret_data.shape (1906, 162)\n",
      "ret_data.shape (2281, 162)\n",
      "ret_data.shape (2560, 162)\n",
      "ret_data.shape (2086, 162)\n",
      "ret_data.shape (5620, 162)\n",
      "ret_data.shape (1711, 162)\n",
      "ret_data.shape (1425, 162)\n",
      "ret_data.shape (1302, 162)\n",
      "ret_data.shape (1993, 162)\n",
      "ret_data.shape (2027, 162)\n",
      "ret_data.shape (1749, 162)\n",
      "ret_data.shape (2936, 162)\n",
      "ret_data.shape (2008, 162)\n",
      "ret_data.shape (5750, 162)\n",
      "categorical feature: ['mean_cat']\n",
      "x_tr.shape (5722, 1447) , x_te.shape (5914, 1447)\n",
      "train type: <class 'pandas.core.frame.DataFrame'>\n",
      "test type: <class 'pandas.core.frame.DataFrame'>\n",
      "y type: <class 'pandas.core.series.Series'>\n",
      "features type: <class 'pandas.core.indexes.base.Index'>\n"
     ]
    }
   ],
   "source": [
    "model = 'baseline3'\n",
    "print('baseline model:', model)\n",
    "\n",
    "\n",
    "TOTAL_THRES = 300 # 구매액 임계값\n",
    "SEED = 42 # 랜덤 시드\n",
    "seed_everything(SEED) # 시드 고정\n",
    "\n",
    "\n",
    "data_dir = './input' \n",
    "model_dir = './model'\n",
    "output_dir = './output'\n",
    "\n",
    "\n",
    "# 데이터 파일 읽기\n",
    "data = pd.read_csv(data_dir + '/train.csv', parse_dates=['order_date'])\n",
    "\n",
    "# 예측할 연월 설정\n",
    "year_month = '2011-12'\n",
    "\n",
    "\n",
    "period_rule = [(\"m\", 1, 0), (\"m\", 2, 1), (\"m\", 3, 2), (\"m\", 6, 3), (\"m\", 9, 6), (\"m\", 12, 9), (\"m\", 15, 12), (\"m\", 18, 15), ('m', 22, 0)]\n",
    "feature_rule = [\n",
    "    agg_dict for _ in range(len(period_rule))\n",
    "]\n",
    "\n",
    "\n",
    "# 피처 엔지니어링 실행\n",
    "train, test, y, features = feature_engineering4(data, year_month, '2011-11', period_rule, feature_rule, 300)\n",
    "\n",
    "\n",
    "print(f\"train type: {type(train)}\")\n",
    "print(f\"test type: {type(test)}\")\n",
    "print(f\"y type: {type(y)}\")\n",
    "print(f\"features type: {type(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d695d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, x_tr.shape: (5149, 1444), x_val.shape: (573, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999633\tvalid_1's auc: 0.802354\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.898671\tvalid_1's auc: 0.822659\n",
      "Fold 1 | AUC: 0.8226594602598748\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 2, x_tr.shape: (5149, 1444), x_val.shape: (573, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.99958\tvalid_1's auc: 0.797301\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's auc: 0.948124\tvalid_1's auc: 0.807963\n",
      "Fold 2 | AUC: 0.8079628327101765\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 3, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999587\tvalid_1's auc: 0.823565\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.926938\tvalid_1's auc: 0.842343\n",
      "Fold 3 | AUC: 0.8423430150078399\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 4, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999584\tvalid_1's auc: 0.81145\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.916779\tvalid_1's auc: 0.830667\n",
      "Fold 4 | AUC: 0.8306671395505114\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 5, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999483\tvalid_1's auc: 0.794702\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.924803\tvalid_1's auc: 0.813651\n",
      "Fold 5 | AUC: 0.8136512883299014\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 6, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999601\tvalid_1's auc: 0.8321\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's auc: 0.992076\tvalid_1's auc: 0.840911\n",
      "Fold 6 | AUC: 0.8409111989166529\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 7, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999606\tvalid_1's auc: 0.795991\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.985364\tvalid_1's auc: 0.808995\n",
      "Fold 7 | AUC: 0.8089951212272988\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 8, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999558\tvalid_1's auc: 0.812826\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.985851\tvalid_1's auc: 0.824197\n",
      "Fold 8 | AUC: 0.8241972285602982\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 9, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999558\tvalid_1's auc: 0.821656\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.930892\tvalid_1's auc: 0.82634\n",
      "Fold 9 | AUC: 0.8263398074461573\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 10, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999553\tvalid_1's auc: 0.811008\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.955107\tvalid_1's auc: 0.837275\n",
      "Fold 10 | AUC: 0.8372753074739828\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Mean AUC = 0.8255002399482694\n",
      "OOF AUC = 0.8185451411631385\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    'objective': 'binary', # 이진 분류\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'auc', # 평가 지표 설정\n",
    "    'feature_fraction': 0.7, # 피처 샘플링 비율\n",
    "    'bagging_fraction': 0.6, # 데이터 샘플링 비율\n",
    "    'bagging_freq': 1,\n",
    "    'n_estimators': 10000, # 트리 개수\n",
    "    'early_stopping_rounds': 300,\n",
    "    'seed': SEED,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "}\n",
    "\n",
    "\n",
    "# Cross Validation Out Of Fold로 LightGBM 모델 훈련 및 예측\n",
    "y_oof, test_preds, fi = make_lgb_oof_prediction(train, y, test, features, model_params=model_params, folds=10)\n",
    "\n",
    "# 테스트 결과 제출 파일 읽기\n",
    "sub = pd.read_csv('./input/sample_submission.csv')\n",
    "\n",
    "# 테스트 예측 결과 저장\n",
    "sub['probability'] = test_preds\n",
    "\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# 제출 파일 쓰기\n",
    "sub.to_csv(os.path.join('output_baseline3_final_4.csv'), index=False)\n",
    "# 1달 단위"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab812e19",
   "metadata": {},
   "source": [
    "## trial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9953bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline model: baseline3\n",
      "ret_data.shape (2175, 162)\n",
      "ret_data.shape (1540, 162)\n",
      "ret_data.shape (1666, 162)\n",
      "ret_data.shape (1573, 162)\n",
      "ret_data.shape (1282, 162)\n",
      "ret_data.shape (2033, 162)\n",
      "ret_data.shape (2560, 162)\n",
      "ret_data.shape (2086, 162)\n",
      "ret_data.shape (5620, 162)\n",
      "ret_data.shape (2446, 162)\n",
      "ret_data.shape (1817, 162)\n",
      "ret_data.shape (1629, 162)\n",
      "ret_data.shape (1579, 162)\n",
      "ret_data.shape (1473, 162)\n",
      "ret_data.shape (1369, 162)\n",
      "ret_data.shape (2936, 162)\n",
      "ret_data.shape (2008, 162)\n",
      "ret_data.shape (5750, 162)\n",
      "categorical feature: ['mean_cat']\n",
      "x_tr.shape (5722, 1447) , x_te.shape (5914, 1447)\n",
      "train type: <class 'pandas.core.frame.DataFrame'>\n",
      "test type: <class 'pandas.core.frame.DataFrame'>\n",
      "y type: <class 'pandas.core.series.Series'>\n",
      "features type: <class 'pandas.core.indexes.base.Index'>\n"
     ]
    }
   ],
   "source": [
    "model = 'baseline3'\n",
    "print('baseline model:', model)\n",
    "\n",
    "\n",
    "TOTAL_THRES = 300 # 구매액 임계값\n",
    "SEED = 42 # 랜덤 시드\n",
    "seed_everything(SEED) # 시드 고정\n",
    "\n",
    "\n",
    "data_dir = './input' \n",
    "model_dir = './model'\n",
    "output_dir = './output'\n",
    "\n",
    "\n",
    "# 데이터 파일 읽기\n",
    "data = pd.read_csv(data_dir + '/train.csv', parse_dates=['order_date'])\n",
    "\n",
    "# 예측할 연월 설정\n",
    "year_month = '2011-12'\n",
    "\n",
    "\n",
    "period_rule = [(\"m\", 2, 0), (\"m\", 4, 2), (\"m\", 6, 4), (\"m\", 8, 6), (\"m\", 10, 8), (\"m\", 12, 10), (\"m\", 15, 12), (\"m\", 18, 15), ('m', 22, 0)]\n",
    "feature_rule = [\n",
    "    agg_dict for _ in range(len(period_rule))\n",
    "]\n",
    "\n",
    "\n",
    "# 피처 엔지니어링 실행\n",
    "train, test, y, features = feature_engineering4(data, year_month, '2011-11', period_rule, feature_rule, 300)\n",
    "\n",
    "\n",
    "print(f\"train type: {type(train)}\")\n",
    "print(f\"test type: {type(test)}\")\n",
    "print(f\"y type: {type(y)}\")\n",
    "print(f\"features type: {type(features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa9d5927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1, x_tr.shape: (5149, 1444), x_val.shape: (573, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999645\tvalid_1's auc: 0.808333\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's auc: 0.947007\tvalid_1's auc: 0.82141\n",
      "Fold 1 | AUC: 0.8214100618220856\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 2, x_tr.shape: (5149, 1444), x_val.shape: (573, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999564\tvalid_1's auc: 0.804557\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's auc: 0.946067\tvalid_1's auc: 0.813034\n",
      "Fold 2 | AUC: 0.8130344648872765\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 3, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999588\tvalid_1's auc: 0.823602\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.894222\tvalid_1's auc: 0.840775\n",
      "Fold 3 | AUC: 0.8407750317329948\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 4, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999529\tvalid_1's auc: 0.79157\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.928864\tvalid_1's auc: 0.825002\n",
      "Fold 4 | AUC: 0.8250018666467558\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 5, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999449\tvalid_1's auc: 0.797856\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's auc: 0.992825\tvalid_1's auc: 0.818651\n",
      "Fold 5 | AUC: 0.8186506390635724\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 6, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999582\tvalid_1's auc: 0.837461\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.906782\tvalid_1's auc: 0.842664\n",
      "Fold 6 | AUC: 0.8426642180050828\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 7, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999599\tvalid_1's auc: 0.780353\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.954835\tvalid_1's auc: 0.800267\n",
      "Fold 7 | AUC: 0.8002671267182371\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 8, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999581\tvalid_1's auc: 0.821656\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.952636\tvalid_1's auc: 0.831562\n",
      "Fold 8 | AUC: 0.831561763778359\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 9, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999589\tvalid_1's auc: 0.832155\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.93419\tvalid_1's auc: 0.84681\n",
      "Fold 9 | AUC: 0.846810247277719\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 10, x_tr.shape: (5150, 1444), x_val.shape: (572, 1444)\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's auc: 0.999565\tvalid_1's auc: 0.829095\n",
      "[400]\ttraining's auc: 0.99999\tvalid_1's auc: 0.833343\n",
      "Early stopping, best iteration is:\n",
      "[291]\ttraining's auc: 0.999898\tvalid_1's auc: 0.835328\n",
      "Fold 10 | AUC: 0.8353275084868385\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Mean AUC = 0.8275502928418922\n",
      "OOF AUC = 0.811100268974111\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    'objective': 'binary', # 이진 분류\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'auc', # 평가 지표 설정\n",
    "    'feature_fraction': 0.7, # 피처 샘플링 비율\n",
    "    'bagging_fraction': 0.6, # 데이터 샘플링 비율\n",
    "    'bagging_freq': 1,\n",
    "    'n_estimators': 10000, # 트리 개수\n",
    "    'early_stopping_rounds': 300,\n",
    "    'seed': SEED,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "}\n",
    "\n",
    "\n",
    "# Cross Validation Out Of Fold로 LightGBM 모델 훈련 및 예측\n",
    "y_oof, test_preds, fi = make_lgb_oof_prediction(train, y, test, features, model_params=model_params, folds=10)\n",
    "\n",
    "# 테스트 결과 제출 파일 읽기\n",
    "sub = pd.read_csv('./input/sample_submission.csv')\n",
    "\n",
    "# 테스트 예측 결과 저장\n",
    "sub['probability'] = test_preds\n",
    "\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# 제출 파일 쓰기\n",
    "sub.to_csv(os.path.join('output_baseline3_final_5.csv'), index=False)\n",
    "# 2달 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04286335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
