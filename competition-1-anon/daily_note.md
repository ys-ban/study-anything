최종스코어 accuracy 77.98%, f1 0.7300

본 마크다운은 데이터셋, 모델, 평가지표, 결과를 주축으로 작성됩니다.

# Day 1
- 데이터셋
    - 파일 데이터 구조 파악
    - 내부 파일 갯수 파악
    - 각 파일 확장자 파악
    - 데이터 경로에 따른 라벨링
    - 상세 데이터 분류 기준 파악
        - 특성1(3가지), 특성2(3가지), 특성3(2가지), 총 18개의 레이블
    - 세 개의 분류 기준에 따른 데이터 수량 파악
    - 실제 이미지 확인을 통한 특성 파악
    - 18개의 데이터 세그멘트에 따라 비슷한 수량으로 증강 필요
    - 확인한 모든 이미지는 비슷한 특성 보유(대상의 위치, 직접 보여지는 형태)
    
- 모델
    - 18개의 레이블을 분류하기 위해 총 3개의 모델을 제작
    - 비교적 간단한 분류 문제이므로 작은 모델을 이용한 전이학습
    - 세 모델의 추론결과를 활용한 예측 객체 필요

- 평가지표
    - 각 모델을 cross entropy를 활용하여 갱신
    - recall을 평가지표로 활용

- 결과
    - 없음


# Day 2
- 데이터셋
    - 데이터의 경로를 입력으로 받는 데이터셋 구성
    - 모델에 따라 출력하는 레이블이 다름
    -  augmentation으로 적용
        - random perspective
        - random rotation
        - random saturation
        - random hue
        - random contrast
    - 증강은 없음

- 모델
    - 가볍지만 높은 정확도를 보이는 모델 위주로 선택
        - inception v3
        - efficientnet b3
        - resnet 34
        - resnet 50
    - inception v3 사용(비교적 가벼우면서 벤치마크 성적이 우수)
    - 전이학습을 이용
    - 모두 맨 마지막 classifier의 output channel이 1000개
        - 1000에서 n개로 보내는 레이어 추가
        - 1000개를 분류하는 레이어를 n개를 분류하는 레이어로 변경
    - 이전 학습된 특성을 보전하기 위해 1000개를 n개로 보내는 레이어 추가
    - 마지막 레이어와 backbone의 레이어 사이에 dropout(확률 0.5)을 사용
    - 세 개의 모델을 사용하여 최종 레이블을 산출하는 Predicter class 작성

- 평가지표
    - 변함 없음

- 결과
    - LB 상 accuracy는 74.41%, f1은 0.68
    


# Day 3
- 데이터셋
    - 데이터 불균형으로 인해 성능이 충분히 나오지 않음
    - 각 레이블에 해당하는 모든 데이터가 5000개 이상이 되도록 증강
    - 증강 결과 총 데이터가 약 12만개
    - 각 데이터에 여러 증강 기법을 무작위로 적용

- 모델
    - 변함 없음
    
- 평가지표
    - 변함 없음
    
- 결과
    - LB 상 accuracy는 77.35%, f1은 0.71


# Day 4
- 데이터셋
    - augmentation에 normalize, random gray scale 추가
    - stratified k fold를 적용
    - 특성1의 레이블을 3개에서 10개로 세분화
    
- 모델
    - 변함 없음
    
- 평가지표
    - 변함 없음

- 결과
    - 2 에폭 이후 LB 상 accuracy는 77.98%, f1은 0.73


# Day 5
- 데이터셋
    - augmentation에 center crop(384\*384) 적용

- 모델
    - 각 레이블을 예측하는 모델을 변경하며 최적의 예측 조합을 탐색
    - 각 모델이 n 에폭을 학습하면 그 세제곱만큼의 경우의 수가 발생하는 문제점

- 평가지표
    - 변함 없음

- 결과
    - 모든 조합이 이전 결과를 능가하지 못함
    - 세 모델 중 두 개의 모델(특성2, 특성3)은 적은 학습으로 충분히 높은 성능을 냄
    - 나머지 한 모델(특성1)의 성능이 개선되지 않음


# Day 6
- 데이터셋
    - 변함 없음

- 모델
    - resnet50으로 backbone을 변경하여 진행
    - 세 모델 중 특성1에 대한 모델만 향상시키면 됨
    - 나머지 두 특성은 쉽게 포화

- 평가지표
    - 변함 없음

- 결과
    - 이전에 비해 하락
    

# Day 7
- 데이터셋
    - over sampling 없이 stratified k fold를 사용
    - 18개의 레이블에서 7개 레이블로 변경
    - random grid shiffle 추가

- 모델
    - multi class classification에서 multi label classification으로 변경(모델의 복잡성을 높혀 태스크를 복잡하게, 일반화 성능은 우수하게)
    - backbone을 efficientnet b3로 변경(inception v3에 비해 벤치마크 성적 우수, 파라미터의 갯수 유사)

- 평가지표
    - multi label soft margin loss를 활용하여 갱신
    - f1, recall, precision을 사용

- 결과
    - 7개 레이블 중 2개의 레이블(특성1)의 평균 f1이 0.75를 넘기지 못함


# Day 8
- 데이터셋
    - train/validation으로 나누지 않음
    - 모든 데이터를 학습에 사용

- 모델
    - 특성1을 위한 모델
    - efficientnet b3를 전이학습
    - 1000의 값으로 3개를 예측하는 레이어 추가
    - 특성3의 값이 0일 때 사용할 모델, 특성3의 값이 1일 때 모델로 특성1 분류기 세분화
    - dropout확률값을 기존 0.5에서 0.7로 변경(일반화 성능을 위한 시도)

- 평가지표
    - cross entropy
    - recall, precision, f1

- 결과
    - Adam, lr=1e-3, 1e-4으로 학습시 한 에폭만에 과적합이 발생함
    - SGD, lr=1e-3으로 학습시 다섯 에폭 학습 후에도 적합을 못함
    - Adam, lr=1e-6으로 학습시 과적합이 안 일어나면서 SGD보다 빠르게 수렴함
    - 모든 학습 상황에서 스케쥴러는 CosineAnnealingWarmRestarts, 주기 10, 최소 lr=1e-8 적용
    - 최악의 결과(최하위 10% 정도의 결과)


# Day 9
- 데이터셋
  - train/validation 8:2로 분할하여학습
  - data leak 없음

- 모델
  - 기존 모델의 조합을 변경하며 실험
  - ensemble 적용(voting)

- 결과
  - 약간의 상승은 있었지만 큰 개선은 없었음



